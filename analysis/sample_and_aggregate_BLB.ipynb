{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load in CSV and randomly assign rows to a partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = \"data/PUMS_california_demographics_1000/data.csv\"\n",
    "df5 = spark.read.load(filepath, format=\"csv\", sep=\",\"\n",
    "                    ,inferSchema=\"true\", header=\"true\")\n",
    "num_partitions = 25\n",
    "df5 = df5.withColumn(\"random\",rand())\n",
    "df5 = df5.repartitionByRange(num_partitions, \"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----+------+-------+--------------------+\n",
      "|age|sex|educ|race|income|married|              random|\n",
      "+---+---+----+----+------+-------+--------------------+\n",
      "| 58|  0|  13|   1| 60900|      1| 0.02260264856177685|\n",
      "| 46|  1|  13|   1| 47000|      1| 0.03187375684198912|\n",
      "| 40|  0|  13|   1|149000|      0|0.003939459108912358|\n",
      "| 23|  0|  11|   1| 66000|      0|0.023179592655977355|\n",
      "| 82|  1|   9|   3|   690|      0| 0.03316615433891279|\n",
      "| 48|  1|  12|   1|  6800|      0|0.023148339591709144|\n",
      "| 66|  0|  16|   1|120000|      1| 0.01246869426324404|\n",
      "| 28|  1|   2|   3|     0|      1| 0.03519417148590831|\n",
      "| 59|  0|  13|   1| 30000|      1|0.005068340765637114|\n",
      "| 47|  1|  13|   1| 75800|      0|0.004785087357865314|\n",
      "| 29|  0|   9|   1| 40000|      1| 0.02093951166607999|\n",
      "| 46|  0|   9|   1|  9500|      0|0.034263355225832015|\n",
      "| 78|  1|  13|   4| 29300|      1|0.019628224499870894|\n",
      "| 38|  0|  12|   3| 40000|      1|1.402972422714921E-4|\n",
      "| 30|  0|   8|   1| 50000|      1|0.009609894149315679|\n",
      "| 70|  1|   9|   1|  7000|      1|0.003624480881464942|\n",
      "| 62|  1|  10|   3| 70000|      1| 0.01615459334826741|\n",
      "| 40|  1|   8|   3| 10500|      1|0.017047746358309968|\n",
      "| 42|  1|  13|   1|  2500|      0|0.028342498801949723|\n",
      "| 30|  0|  11|   4| 36500|      1|0.004703547327005064|\n",
      "+---+---+----+----+------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each partition, run the estimator, and collect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mean(partition):\n",
    "    psum = 0\n",
    "    rows = 0\n",
    "    for row in partition: \n",
    "        psum = psum + row[0]\n",
    "        rows = rows + 1\n",
    "    yield (psum/rows )\n",
    "    \n",
    "    \n",
    "def weightedMean(values, weights):\n",
    "    valSum = 0\n",
    "    wtSum = 0;\n",
    "    for i in range(len(values)):\n",
    "        valSum = valSum + (values[i] * weights[i]);\n",
    "        wtSum = wtSum + weights[i]\n",
    "    return valSum/wtSum\n",
    "    \n",
    "    \n",
    "#Bootstrap parameters\n",
    "N = df5.count()  # size of dataset for generating weights\n",
    "r = 50           # number of bootstrap runs for each partition\n",
    "weightedEstimator = weightedMean  # function to calc QOI in bootstrap\n",
    "\n",
    "def sample_and_aggregate_BLB(partition):\n",
    "    # get array of values from partition\n",
    "    pList = list(partition)\n",
    "    pLen = len(pList)\n",
    "    vals = [None] * pLen   \n",
    "    for i in range(pLen):\n",
    "         # fill array with [0] element of Row      \n",
    "        vals[i] = pList[i][0]\n",
    "        \n",
    "    # sample multinomial to get array of weights       \n",
    "    weights = np.random.multinomial(N, [1/pLen]*pLen, size=r)\n",
    "    \n",
    "    #get the QOI for each run\n",
    "    results = [None] * r\n",
    "    for i in range(r):     \n",
    "        results[i] = weightedEstimator(vals, weights[i])\n",
    "    # return the mean of the result for each run\n",
    "    yield np.mean(results)\n",
    "   \n",
    "    \n",
    "means = df5.select(\"age\").rdd.mapPartitions(sample_and_aggregate_BLB).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Compare mean of bootstrap means to the mean of the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.7960488\n",
      "[Row(avg(age)=44.797)]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(means))\n",
    "print(df5.select(avg(\"age\")).collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
