{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Queries with Differentially Private Set Union (DPSU)\n",
    "\n",
    "In the context of the WhiteNoise SQL scenario, consider a guiding example: there exists a dataset with Reddit users and their posts, keeping in mind that a single user could have multiple posts. An analyst would like to release a report containing the counts of the number of bigrams per user while preserving privacy. We'd like to increase the representation of bigrams contained in this report without violating privacy bounds.\n",
    "\n",
    "You can imagine that it might be easy to identify an author's bigrams if she has only posted a few times and therefore has very few bigrams. To resolve this threat, previously, we would have to drop bigrams whose noisy counts were below a certain threshold. However, this process was wasteful because we allocated privacy budget to all rows uniformly even if their counts already exceeded the threshold.\n",
    "\n",
    "With DPSU, we resolve this issue by adding noise in a dependent fashion. This increases the dimensionality of the final dataset, and we therefore have less data loss and get a richer representation of bigrams. \n",
    "\n",
    "The code below showcases DPSU support with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205092\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from opendp.whitenoise.metadata import CollectionMetadata\n",
    "from opendp.whitenoise.sql import PrivateReader, PandasReader\n",
    "\n",
    "reddit = pd.read_csv(\"../../data/readers/reddit.csv\", index_col=0)\n",
    "metadata = CollectionMetadata.from_file(\"../../data/readers/reddit.yaml\")\n",
    "\n",
    "query = \"SELECT ngram, COUNT(*) as n FROM reddit.reddit GROUP BY ngram ORDER BY n desc\"\n",
    "\n",
    "reader = PandasReader(metadata, reddit)\n",
    "exact = reader.execute(query)\n",
    "print(len(exact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ngram         |n      \n",
      " --------------|-------\n",
      "  (n, t)       | 128   \n",
      "  (i, m)       | 66    \n",
      "  (it, s)      | 64    \n",
      "  (that, s)    | 55    \n",
      "  (in, the)    | 53    \n",
      "  (i, was)     | 41    \n",
      "  (do, n)      | 36    \n",
      "  (mom, left)  | 35    \n"
     ]
    }
   ],
   "source": [
    "private_reader = PrivateReader(metadata, reader)\n",
    "result = private_reader.execute_typed(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(result['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ngram       |n      \n",
      " ------------|-------\n",
      "  (n, t)     | 128   \n",
      "  (i, m)     | 84    \n",
      "  (it, s)    | 78    \n",
      "  (do, n)    | 59    \n",
      "  (in, the)  | 50    \n"
     ]
    }
   ],
   "source": [
    "private_reader_korolova = PrivateReader(metadata, reader)\n",
    "private_reader_korolova.options.use_dpsu = False\n",
    "private_reader_korolova.options.max_contrib = 5\n",
    "korolova_result = private_reader_korolova.execute_typed(query)\n",
    "print(korolova_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(korolova_result['n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Module with DPSU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opendp.whitenoise.client import get_execution_client\n",
    "\n",
    "execution_client = get_execution_client()\n",
    "\n",
    "project = {\"params\": {\"dataset_name\": \"reddit\", \n",
    "                      \"budget\": 0.5,\n",
    "                      \"query\": \"SELECT ngram, COUNT(*) as c FROM reddit.reddit GROUP BY ngram ORDER BY c desc\"},\n",
    "           \"uri\": \"modules/sql-module\"}\n",
    "\n",
    "response = execution_client.submit(params=project[\"params\"],\n",
    "                            uri=project[\"uri\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = json.loads(response.result)\n",
    "pd.DataFrame.from_dict(json_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
